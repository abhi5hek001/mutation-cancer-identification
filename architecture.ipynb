{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7b847d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Architecture:\n",
      "\n",
      "DualTaskClassifier(\n",
      "  (conv1): Conv1d(17, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "  (conv2): Conv1d(64, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "  (conv3): Conv1d(128, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "  (pool): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (bn3): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (dropout): Dropout(p=0.3, inplace=False)\n",
      "  (attention): MultiheadAttention(\n",
      "    (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
      "  )\n",
      "  (fc_mutation1): Linear(in_features=256, out_features=128, bias=True)\n",
      "  (fc_mutation2): Linear(in_features=128, out_features=3, bias=True)\n",
      "  (fc_cancer1): Linear(in_features=256, out_features=128, bias=True)\n",
      "  (fc_cancer2): Linear(in_features=128, out_features=3, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Define the model class\n",
    "class DualTaskClassifier(nn.Module):\n",
    "    def __init__(self, num_mutation_classes, num_cancer_classes, input_channels=5):\n",
    "        super(DualTaskClassifier, self).__init__()\n",
    "        \n",
    "        self.input_channels = input_channels\n",
    "        \n",
    "        self.conv1 = nn.Conv1d(input_channels, 64, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv1d(64, 128, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv1d(128, 256, kernel_size=3, padding=1)\n",
    "        \n",
    "        self.pool = nn.MaxPool1d(2)\n",
    "        \n",
    "        self.bn1 = nn.BatchNorm1d(64)\n",
    "        self.bn2 = nn.BatchNorm1d(128)\n",
    "        self.bn3 = nn.BatchNorm1d(256)\n",
    "\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "\n",
    "        self.attention = nn.MultiheadAttention(embed_dim=256, num_heads=4, batch_first=True)\n",
    "        \n",
    "        self.fc_mutation1 = nn.Linear(256, 128)\n",
    "        self.fc_mutation2 = nn.Linear(128, num_mutation_classes)\n",
    "        \n",
    "        self.fc_cancer1 = nn.Linear(256, 128)\n",
    "        self.fc_cancer2 = nn.Linear(128, num_cancer_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, _, seq_len = x.shape\n",
    "\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.pool(x)\n",
    "\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = self.pool(x)\n",
    "\n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "        x = self.pool(x)\n",
    "\n",
    "        x_attn = x.permute(0, 2, 1)\n",
    "        attn_output, _ = self.attention(x_attn, x_attn, x_attn)\n",
    "        x = x + attn_output.permute(0, 2, 1)\n",
    "\n",
    "        x = torch.mean(x, dim=2)\n",
    "        \n",
    "        shared_feat = self.dropout(x)\n",
    "        \n",
    "        mutation_feat = F.relu(self.fc_mutation1(shared_feat))\n",
    "        mutation_feat = self.dropout(mutation_feat)\n",
    "        mutation_out = self.fc_mutation2(mutation_feat)\n",
    "        \n",
    "        cancer_feat = F.relu(self.fc_cancer1(shared_feat))\n",
    "        cancer_feat = self.dropout(cancer_feat)\n",
    "        cancer_out = self.fc_cancer2(cancer_feat)\n",
    "        \n",
    "        return mutation_out, cancer_out\n",
    "\n",
    "# Instantiate the model (update these numbers if needed)\n",
    "num_mutation_classes = 3  # Example: change based on your dataset\n",
    "num_cancer_classes = 3    # Example: change based on your dataset\n",
    "input_channels = 17        # Or 17 if using extra features\n",
    "\n",
    "model = DualTaskClassifier(num_mutation_classes, num_cancer_classes, input_channels)\n",
    "\n",
    "# Load weights\n",
    "model.load_state_dict(torch.load(\"cancer_and_mutation_type_classifier.pth\", map_location='cpu'))\n",
    "\n",
    "# Print architecture\n",
    "print(\"Model Architecture:\\n\")\n",
    "print(model)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
